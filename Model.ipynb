{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1,'./crnn.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class strLabelConverter(object):\n",
    "    \"\"\"Convert between str and label.\n",
    "    NOTE:\n",
    "        Insert `blank` to the alphabet for CTC.\n",
    "    Args:\n",
    "        alphabet (str): set of the possible characters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, ignore_case=True):\n",
    "        self._ignore_case = ignore_case\n",
    "        if self._ignore_case:\n",
    "            alphabet = alphabet.lower()\n",
    "        self.alphabet = alphabet + '-'  # for `-1` index\n",
    "\n",
    "        self.dict = {}\n",
    "        for i, char in enumerate(alphabet):\n",
    "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
    "            self.dict[char] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = '零壹貳參肆伍陸柒捌玖拾佰仟萬億兆元整'\n",
    "alphabet = alphabet + '-'\n",
    "alphabet_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
    "    alphabet_dict[char] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../datamartV1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root</th>\n",
       "      <th>Amount</th>\n",
       "      <th>image</th>\n",
       "      <th>Amount_hw</th>\n",
       "      <th>image_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/image/data/GF10244160490032.jpg</td>\n",
       "      <td>16000</td>\n",
       "      <td>[[0.7254901960784313, 0.7176470588235294, 0.70...</td>\n",
       "      <td>壹萬陸仟元整</td>\n",
       "      <td>[[0.7205575980392156, 0.6301623774509804, 0.62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/image/data/GF11241974690049.jpg</td>\n",
       "      <td>2468</td>\n",
       "      <td>[[0.5254901960784314, 0.49411764705882355, 0.5...</td>\n",
       "      <td>貳仟肆佰陸拾捌元整</td>\n",
       "      <td>[[0.6123468137254902, 0.8616268382352941, 0.73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/image/data/GF11012970590053.jpg</td>\n",
       "      <td>9545</td>\n",
       "      <td>[[0.7294117647058823, 0.7058823529411765, 0.66...</td>\n",
       "      <td>玖仟伍佰肆拾伍元整</td>\n",
       "      <td>[[0.6418504901960784, 0.8431066176470589, 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/image/data/GF10336156190068.jpg</td>\n",
       "      <td>16870</td>\n",
       "      <td>[[0.8470588235294118, 0.8470588235294118, 0.82...</td>\n",
       "      <td>壹萬陸仟捌佰柒拾元整</td>\n",
       "      <td>[[0.5708026960784315, 0.7798253676470588, 0.66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/image/data/GF11366206090092.jpg</td>\n",
       "      <td>9000</td>\n",
       "      <td>[[0.9019607843137255, 0.9647058823529412, 0.93...</td>\n",
       "      <td>玖仟元整</td>\n",
       "      <td>[[0.8944087009803922, 0.8486366421568629, 0.85...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               root  Amount  \\\n",
       "0  /image/data/GF10244160490032.jpg   16000   \n",
       "1  /image/data/GF11241974690049.jpg    2468   \n",
       "2  /image/data/GF11012970590053.jpg    9545   \n",
       "3  /image/data/GF10336156190068.jpg   16870   \n",
       "4  /image/data/GF11366206090092.jpg    9000   \n",
       "\n",
       "                                               image   Amount_hw  \\\n",
       "0  [[0.7254901960784313, 0.7176470588235294, 0.70...      壹萬陸仟元整   \n",
       "1  [[0.5254901960784314, 0.49411764705882355, 0.5...   貳仟肆佰陸拾捌元整   \n",
       "2  [[0.7294117647058823, 0.7058823529411765, 0.66...   玖仟伍佰肆拾伍元整   \n",
       "3  [[0.8470588235294118, 0.8470588235294118, 0.82...  壹萬陸仟捌佰柒拾元整   \n",
       "4  [[0.9019607843137255, 0.9647058823529412, 0.93...        玖仟元整   \n",
       "\n",
       "                                         image_Small  \n",
       "0  [[0.7205575980392156, 0.6301623774509804, 0.62...  \n",
       "1  [[0.6123468137254902, 0.8616268382352941, 0.73...  \n",
       "2  [[0.6418504901960784, 0.8431066176470589, 0.70...  \n",
       "3  [[0.5708026960784315, 0.7798253676470588, 0.66...  \n",
       "4  [[0.8944087009803922, 0.8486366421568629, 0.85...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df.Amount_hw.apply(lambda x : np.array([alphabet_dict[i] for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i.reshape(1,32,320) for i in df.image_Small.values])\n",
    "y = np.array([i for i in df.Label.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X).type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: double, float, float16, int64, int32, and uint8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c901874e1640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: double, float, float16, int64, int32, and uint8."
     ]
    }
   ],
   "source": [
    "y = torch.FloatTensor(y).type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.60189951, 0.43137255, 0.45009191, ..., 0.65294118,\n",
       "          0.71352635, 0.77058824],\n",
       "         [0.75073529, 0.68895527, 0.66236213, ..., 0.65294118,\n",
       "          0.71053922, 0.77083333],\n",
       "         [0.70863971, 0.69319853, 0.70292586, ..., 0.667356  ,\n",
       "          0.69921875, 0.76530331],\n",
       "         ...,\n",
       "         [0.6379902 , 0.68871017, 0.62867647, ..., 0.61495098,\n",
       "          0.63086703, 0.70914522],\n",
       "         [0.6560815 , 0.64401042, 0.61668199, ..., 0.61617647,\n",
       "          0.62608762, 0.71098346],\n",
       "         [0.64436275, 0.66985294, 0.62311581, ..., 0.60188419,\n",
       "          0.61847426, 0.65886949]]],\n",
       "\n",
       "\n",
       "       [[[0.54316789, 0.88434436, 0.40617341, ..., 0.79681373,\n",
       "          0.81793811, 0.79727328],\n",
       "         [0.83540135, 0.80251225, 0.37161458, ..., 0.85004596,\n",
       "          0.81541054, 0.80073529],\n",
       "         [0.79898897, 0.76311275, 0.80386029, ..., 0.81574755,\n",
       "          0.82768076, 0.78651961],\n",
       "         ...,\n",
       "         [0.81636029, 0.84276961, 0.78465074, ..., 0.77745098,\n",
       "          0.77032782, 0.75605086],\n",
       "         [0.78259804, 0.76424632, 0.76320466, ..., 0.79973958,\n",
       "          0.79191176, 0.74048713],\n",
       "         [0.760769  , 0.80916054, 0.76404718, ..., 0.76593137,\n",
       "          0.75808824, 0.71348039]]],\n",
       "\n",
       "\n",
       "       [[[0.53979779, 0.44159007, 0.68318015, ..., 0.72671569,\n",
       "          0.74117647, 0.70637255],\n",
       "         [0.56395527, 0.76997549, 0.5314185 , ..., 0.72671569,\n",
       "          0.74117647, 0.70637255],\n",
       "         [0.47262561, 0.73103554, 0.49883578, ..., 0.72388174,\n",
       "          0.74630821, 0.71257659],\n",
       "         ...,\n",
       "         [0.76596201, 0.74473039, 0.72503064, ..., 0.74117647,\n",
       "          0.66985294, 0.67058824],\n",
       "         [0.75562194, 0.67994792, 0.68581495, ..., 0.701394  ,\n",
       "          0.64520527, 0.6479473 ],\n",
       "         [0.70292586, 0.69705882, 0.76095282, ..., 0.65759804,\n",
       "          0.63872549, 0.64142157]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.79900429, 0.79750306, 0.73140319, ..., 0.76234681,\n",
       "          0.75735294, 0.75612745],\n",
       "         [0.64480699, 0.75828738, 0.74053309, ..., 0.76343444,\n",
       "          0.76040135, 0.7551011 ],\n",
       "         [0.6291973 , 0.78523284, 0.76000306, ..., 0.68011642,\n",
       "          0.73829657, 0.74428615],\n",
       "         ...,\n",
       "         [0.76946998, 0.76795343, 0.80549939, ..., 0.75111826,\n",
       "          0.75588235, 0.79460784],\n",
       "         [0.7182598 , 0.73409926, 0.80150123, ..., 0.75588235,\n",
       "          0.76116728, 0.79636949],\n",
       "         [0.70931373, 0.73137255, 0.8004902 , ..., 0.71593137,\n",
       "          0.72348346, 0.75882353]]],\n",
       "\n",
       "\n",
       "       [[[0.62005208, 0.8370098 , 0.75497855, ..., 0.69044118,\n",
       "          0.67765012, 0.66640625],\n",
       "         [0.61001838, 0.86740196, 0.57244179, ..., 0.66838235,\n",
       "          0.68469669, 0.6765625 ],\n",
       "         [0.86338848, 0.85543811, 0.83514093, ..., 0.65899203,\n",
       "          0.67734375, 0.66986826],\n",
       "         ...,\n",
       "         [0.73929228, 0.73920037, 0.69607843, ..., 0.63837316,\n",
       "          0.63995098, 0.60752145],\n",
       "         [0.74088542, 0.74289216, 0.6899663 , ..., 0.63651961,\n",
       "          0.63102022, 0.60563725],\n",
       "         [0.70837929, 0.76354167, 0.72892157, ..., 0.61904105,\n",
       "          0.61515012, 0.58650429]]],\n",
       "\n",
       "\n",
       "       [[[0.81884191, 0.82284007, 0.8509038 , ..., 0.83014706,\n",
       "          0.83783701, 0.82273284],\n",
       "         [0.82221201, 0.82328431, 0.81171875, ..., 0.8497549 ,\n",
       "          0.8459712 , 0.83927696],\n",
       "         [0.80588235, 0.7902114 , 0.82195159, ..., 0.85479473,\n",
       "          0.83440564, 0.84803922],\n",
       "         ...,\n",
       "         [0.79767157, 0.78132659, 0.69250919, ..., 0.80018382,\n",
       "          0.81763174, 0.8261489 ],\n",
       "         [0.81487439, 0.75111826, 0.77757353, ..., 0.81666667,\n",
       "          0.83137255, 0.82598039],\n",
       "         [0.82691483, 0.77405025, 0.83619792, ..., 0.76976103,\n",
       "          0.81397059, 0.81493566]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 5, 14, 17, 18]), array([ 4, 14, 17, 18]),\n",
       "       array([ 5, 14, 17, 18]), ...,\n",
       "       array([ 2, 12,  6, 11,  5, 14,  9, 13,  5, 12,  4, 11,  6, 17, 18]),\n",
       "       array([ 2, 12,  2, 11, 10, 14,  9, 13,  6, 12,  6, 11,  8, 17, 18]),\n",
       "       array([ 4, 13,  5, 12, 10, 11, 14,  2, 13,  8, 12,  4, 11,  3, 17, 18])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.size(),y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = Data.TensorDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable = Variable(X, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(torch_dataset, batch_size=batchSize,\n",
    "                                           shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = crnn.CRNN(32, 1, 19, 256)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"./crnn.pytorch/data/crnnV2.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(batchSize, 1, 32, 32)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.cuda()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)\n",
    "image = image.cuda()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01126,betas=(0.01, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    train_iter = iter(train_loader)\n",
    "    i = 0\n",
    "    while i < len(train_loader):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('[iteration%d/%d][%d/%d] ' %\n",
    "                  (epoch, 1000, i, len(train_loader), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './crnn.pytorch/data/crnnV2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open('./crnn.pytorch/data/GF10222057890039.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
